{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Deep Learning Course Notes\n",
    "\n",
    "*This is a place for random small notes on various functions, packages, tips and more*\n",
    "\n",
    "---\n",
    "**Table of Contents**\n",
    "* 00 Jupyter Notebook tutorial\n",
    "* 01 Image Classification\n",
    "    * A. Tips with RegEx \n",
    "* 02 Data Cleaning and Production; SGD from Scratch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    " <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Notebook Tutorial\n",
    "[link to notebook](https://ng8d23p8.gradient.paperspace.com/notebooks/course-v3/nbs/dl1/00_notebook_tutorial-1-my-copy.ipynb)\n",
    "\n",
    "\n",
    "**Cool to do list tricks**\n",
    "\n",
    "- [x] Take notes\n",
    "    - [x] start course\n",
    "\n",
    "1. step 1\n",
    "    2. step 2\n",
    "    \n",
    "* my\n",
    "* name\n",
    "* is \n",
    "\n",
    "**Cool tricks**\n",
    "\n",
    "`m` to change cell to markdown\n",
    "\n",
    "`?function-name` to display parameters\n",
    "\n",
    "`D + D` to delete a cell\n",
    "\n",
    "`esc` to go to command from edit mode\n",
    "\n",
    "`b` create new cell\n",
    "\n",
    "`shift` + `enter`: run current cell\n",
    "\n",
    ">*\"She said do you love me\"*\n",
    "\n",
    "\n",
    "\n",
    "**Display Images**\n",
    "\n",
    "> from PIL import Image <br> Image.open('images/notebook_tutorial/cat_example.jpg')\n",
    "\n",
    "<br> \n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Classification\n",
    "[link to lecture](https://course.fast.ai/videos/?lesson=1) <br>\n",
    "[link to notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson1-pets.ipynb)\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "**Loading the Data**\n",
    "- Untar data function: downloads the dataset as a tgz file and returns the data path to the file \n",
    "- Path data type: POSIX path while path.ls() lists the files in the path\n",
    "- Image data bunch.from_name_re: (some has to do with imagedatabunch and some with the method of retrieval)\n",
    "    - size 224 --> all images must be the same size\n",
    "    - regular expression --> to take fname and convert to a class\n",
    "    - path --> the path to the images\n",
    "    - file names --> names of images \n",
    "    - transforms = crop + resize + padding (data augmentation) the images \n",
    "    - batch size \n",
    "- regular expression: string matching operations to retrieve information [more](https://docs.python.org/3.6/library/re.html)\n",
    "- normalize: Must normalize the data\n",
    "    - each red, blue, green channel need a mean & st.dev of 0 and 1 to perform\n",
    "- Data bunch object (essentially returns a dataloader) \n",
    "    - training data\n",
    "    - validation data\n",
    "    - test data (optional)\n",
    "    - property c = # of classes (or similar) \n",
    "- data.show_batch and data.classes: shows example data points and all classes\n",
    "\n",
    "**Training and fitting**\n",
    "\n",
    "- (Conv)Learner: a type of method that learns and fits data (cnn_learner)\n",
    "    - data | images\n",
    "    - model/architecture | model.resnet34 #solid CNN model with 34 layers\n",
    "    - metrics | error_rate\n",
    "- model.resnet34 = downloads pre-trained resnet34 model which has already gone through 1.5 million various images so has pre-trained weights (this is transfer learning)... allows us to train using 1/100 of the needed data and 1/100 of the time\n",
    "- .fit_one_cycle: better than fit, for some reason. Someone wrote a paper. Param = num of epochs (among other things)\n",
    "- how to test accuracy at 0 epochs?\n",
    "- .save(NAME): saves the model as NAME \n",
    "- .load(NAME);loads a previously saved model\n",
    "\n",
    "\n",
    "- *results* (checking whether mistakes are reasonable can be good)\n",
    "    - ClassificationInterpretation.from_learner(MODEL_NAME) can be used to print top losses\n",
    "    - top losses uses loss function for level of confidence vs. error\n",
    "    - use confusion matrix via interp.plot_confusion_matrix (less helpful when high accuracy)\n",
    "    - interp.most_confused is good\n",
    "\n",
    "**Tuning**\n",
    "\n",
    "- *tuning the model*\n",
    "   - the reason the model trains so quicly at first is that we actually add a few nodes to the end and just train these, leaving the rest of the more complex model alone\n",
    "   - using MODEL.unfreeze() allows us to change the earlier layers of the CNN model --> usually this leads to a lower accuracy at first due to equal learning rate across all layers although earlier layers will naturally be stronger \n",
    "   - CNN works by basing the next layer on simple mathematical combinations of the previous layers.\n",
    "   - useful to plot the learning rate vs. accuracy using MODEL.lr_find() --> Use the chart to set learning rate accordingly\n",
    "   - .fit_one_cycle with max_lr=slice(lower,upper) is helpful --> sets the lr for the layers incrementally according to lower - upper. Good idea is to have a lower LR for lower layers and higher LR for higher layers, since LR corresponds to changes each iteration, and the less accurate layers need more changes. \n",
    "- batch size = number of images computed at one time... lower it if you run out of memory\n",
    "- resnet50 is a deeper CNN... loading with larger size images will lead to more accuracy since more details that model can handle. \n",
    "\n",
    "**Other**\n",
    "\n",
    "\n",
    "- There are other ways to get classes of the data:\n",
    "    - from_folder if each folder is it's own class\n",
    "    - from_csv if labels in a csv file\n",
    "    - from_df if labels in a data frame\n",
    "    - from_name_func allows you to define function that converts name to label\n",
    "    - from_lists if you have a list of the labels\n",
    "\n",
    "\n",
    "- All the documentation on fastai is in a Github repo as Jupyter-notebooks, so you can experiment if necessary. Each has examples so learning from them is easy. \n",
    "\n",
    "\n",
    "**Advice**\n",
    "> \"*Run the code*\" <br> \"*Spend the majority of the time in the notebooks*\"\n",
    "\n",
    "\n",
    "\n",
    "- bring deep learning into my passion\n",
    "\n",
    "\n",
    "**ideas for using deep learning with EA:**\n",
    "    - image recognition:\n",
    "        - NGOs \n",
    "    - natural language processing\n",
    "        - government policy biases \n",
    "        - govenment policy high risk statements and views\n",
    "        - twitter and FB feed: EA-esque statements for targetting \n",
    "        - rich people: EA-esqe views and statements for targetted philanthropy\n",
    "        - government tax invoices: corruption identification\n",
    "    - data analysis\n",
    "        - government funding \n",
    "        - foreign aid budget sheets --> predicting success of program \n",
    "\n",
    "\n",
    "- *other*\n",
    "    - bankruptucy: tax invoice analysis \n",
    "    \n",
    "    - If you can create an image from something that isn't an image, you can then apply CNNs (i.e. tracking mouse movement as an image and classification as real or bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Tips with regular expressions\n",
    "\n",
    "[video on RegEx](https://www.youtube.com/watch?v=DRR9fOXkfRE&feature=youtu.be) \n",
    "\n",
    "#### RegEx\n",
    "*Regular expressions allow us to search text for strings that match some defined expression like searching a list of names for all the Jennifers or selecting all the addresses on a specific street from a list*\n",
    "\n",
    "They can be especially useful for **Machine Learning** as they can be used to scrap data from websites and lists of text\n",
    "\n",
    "An example of a RegEx that searches for all the first and last names of Jennifers would be:\n",
    ">`'(Jennifer|Jen|Jenny)\\b\\w+\\b'`\n",
    "\n",
    "> `|` or \n",
    "<br> `\\b` any line space \n",
    "<br> `w+` 1 or more chars \n",
    "\n",
    "**Furthermore, other useful variables include:**\n",
    "\n",
    "> `\\s` space \n",
    "<br> `d` digit\n",
    "<br> `d{1,5}` 1-5 digits \n",
    "<br> `D` anything but a digit\n",
    "<br> `.` anything\n",
    "<br> `\\.` a period\n",
    "\n",
    "But this is just a few of the countless things RegEx expressions can use\n",
    "\n",
    "**Python Code**\n",
    "> `import re` to import regular expressions\n",
    "<br> `re.compile('w+\\b\\st\\.\\b.')` to define a RegEx for use\n",
    "<br> `re.search(RegEx,String)` to return the first instance of a RegEx in a String\n",
    "<br> `.group()` to return a found instance of a RegEx\n",
    "<br> `.span()` to return the indices which the RegEx was found at in the text (start,end)\n",
    "<br> `.findall(RegEx,String)` to find all instances of a RegEx in a String\n",
    "<br> `.split(String)` to print an array of strings split up by the RegEx (i.e. those that aren't the RegEx)\n",
    "<br> `.sub(TextToSub,String)` to substitute text for the RegEx in a String (RegEx is defined before calling this)\n",
    "\n",
    "This are many more useful ways to implement Regular Expressions. See this [series](https://www.youtube.com/watch?v=FCFdgymqpUI) of videos to continue learning. \n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning and production; SGD from Scratch\n",
    "The first part of this lesson focuses on implementing a CNN model with images scraped from the internet. It goes through the process of locating the images, downloading them, creating the model, training the model and testing the model. It also goes through removing noisy images, saving the model for production, using the model for inference and uploading the model as a web app. Finally, it touches on ways for a CNN model to go wrong. \n",
    "\n",
    "The second part of this lesson has us implement a SGD from Scratch. **Finish This** \n",
    "\n",
    "\n",
    "1. [lecture](https://course.fast.ai/videos/?lesson=2) <br>\n",
    "2. [CNN slides](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb)\n",
    "3. [Gradient Descent slides](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-sgd.ipynb)\n",
    "\n",
    "--- \n",
    "\n",
    "### Data cleaning and production\n",
    "\n",
    "\n",
    "**Get images from google** <br>\n",
    "*This downloads a CSV of all the urls*\n",
    "\n",
    "1. Search Google Images & load all the images you want\n",
    "2. Enter the following code after pressing `cmd-Opt-j`\n",
    ">`urls=Array.from(document.querySelectorAll('.rg_i')).map(el=> el.hasAttribute('data-src')?el.getAttribute('data-src'):el.getAttribute('data-iurl'));` <br> `window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));`\n",
    "\n",
    "**Download images from CSV** <br>\n",
    "*We can use fastai's download_images to save a folder of all the urls downloaded*\n",
    "> `download_images(path/file, dest, max_pics=200,max_workers=0)` #include max_workers = 0 if error\n",
    "\n",
    "Note: `path` is of the format `Path` or PosixPath\n",
    "\n",
    "**Cleaning up** <br>\n",
    "Then *we can use verify_images to filter out all non-images*\n",
    "> `verify_images(path/c, delete=True, max_size=500)` where c is the folder name\n",
    "\n",
    "Finally, we can use `FileDeleter` to go through the `most_confused` and manually delete any noisy images\n",
    "\n",
    "**Using CNN for Inference and a Web App** \n",
    "- ipy widgets can be used to create small applications in notebook that are useful\n",
    "    - Example: FileDeleter allows us to go through images in the notebook, deleting noisy data. \n",
    "- `ImageDataBunch.single_from_classes` loads a pretrained model from specified path and still must apply the `create_cnn` method with same parameters as well as `.load` the right model #you'd do this when loading up the web app\n",
    "- use `learn.predict(img)` to get the predicted label \n",
    "\n",
    "**Things Gone Wrong**\n",
    "1. Learning Rate is too high (i.e. 0.5?)\n",
    "    1. validation loss will be very large\n",
    "2. Learning Rate is too low (i.e. 0.000001)\n",
    "    1. validation loss might be larger than training loss, which means we are not fitting the data\n",
    "    2. The rate of decrease in the validation loss or error is very slow compared to the default\n",
    "> `learn.recorder.plot_losses()` can be used to plot the losses over time \n",
    "3. Too few epochs (i.e. 1)\n",
    "    1. If the training loss is much larger than the validation loss, this is a sign. \n",
    "    2. Solution: Increase # epochs and learning rate (if too slow)\n",
    "4. Overfitting (very hard with CNNs)\n",
    "    1. The sign is that the error gets better and then worse\n",
    "    \n",
    "---\n",
    "\n",
    "### SGD from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## To do\n",
    "\n",
    "* [x] create a Github repo for all of this\n",
    "* [x] apply a CNN to some scraped images\n",
    "* [ ] apply a CNN to something EA related\n",
    "* [ ] imagify some data and then apply a CNN \n",
    "* [ ] create a web app for a CNN\n",
    "    - free hosting can be found online\n",
    "    - starlette is supposed to be good \n",
    "* [ ] create a useful CNN production online (maybe on my website or blog) \n",
    "* [ ] create an ipy widget\n",
    "* [ ] write blog post about CNN applications and first 2 lessons\n",
    "* [ ] contribute to fastai repo \n",
    "* [ ] find an ML mentor\n",
    "* [ ] do a short git version control course\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
