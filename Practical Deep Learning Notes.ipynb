{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Deep Learning Course Notes\n",
    "\n",
    "*This is a place for random small notes on various functions, packages, tips and more*\n",
    "\n",
    "---\n",
    "**Table of Contents**\n",
    "* 00 Jupyter Notebook tutorial\n",
    "* 01 Image Classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    " <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Notebook Tutorial\n",
    "[link to notebook](https://ng8d23p8.gradient.paperspace.com/notebooks/course-v3/nbs/dl1/00_notebook_tutorial-1-my-copy.ipynb)\n",
    "\n",
    "\n",
    "**Cool to do list tricks**\n",
    "\n",
    "- [x] Take notes\n",
    "    - [x] start course\n",
    "\n",
    "1. step 1\n",
    "    2. step 2\n",
    "    \n",
    "* my\n",
    "* name\n",
    "* is \n",
    "\n",
    "**Cool tricks**\n",
    "\n",
    "`m` to change cell to markdown\n",
    "\n",
    "`?function-name` to display parameters\n",
    "\n",
    "`D + D` to delete a cell\n",
    "\n",
    "`esc` to go to command from edit mode\n",
    "\n",
    "`b` create new cell\n",
    "\n",
    "`shift` + `enter`: run current cell\n",
    "\n",
    ">*\"She said do you love me\"*\n",
    "\n",
    "\n",
    "\n",
    "**Display Images**\n",
    "\n",
    "> from PIL import Image <br> Image.open('images/notebook_tutorial/cat_example.jpg')\n",
    "\n",
    "<br> \n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Classification\n",
    "[link to lecture](https://course.fast.ai/videos/?lesson=1)\n",
    "\n",
    "[link to notebook](https://nsxuskr4.gradient.paperspace.com/notebooks/course-v3/nbs/dl1/lesson1-pets-1-my-copy.ipynb)\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "**Loading the Data**\n",
    "- Untar data function: downloads the dataset as a tgz file and returns the data path to the file \n",
    "- Path data type: POSIX path while path.ls() lists the files in the path\n",
    "- Image data bunch.from_name_re: (some has to do with imagedatabunch and some with the method of retrieval)\n",
    "    - size 224 --> all images must be the same size\n",
    "    - regular expression --> to take fname and convert to a class\n",
    "    - path --> the path to the images\n",
    "    - file names --> names of images \n",
    "    - transforms = crop + resize + padding (data augmentation) the images \n",
    "    - batch size \n",
    "- regular expression: string matching operations to retrieve information [more](https://docs.python.org/3.6/library/re.html)\n",
    "- normalize: Must normalize the data\n",
    "    - each red, blue, green channel need a mean & st.dev of 0 and 1 to perform\n",
    "- Data bunch object (essentially returns a dataloader) \n",
    "    - training data\n",
    "    - validation data\n",
    "    - test data (optional)\n",
    "    - property c = # of classes (or similar) \n",
    "- data.show_batch and data.classes: shows example data points and all classes\n",
    "\n",
    "**Training and fitting**\n",
    "\n",
    "- (Conv)Learner: a type of method that learns and fits data (cnn_learner)\n",
    "    - data | images\n",
    "    - model/architecture | model.resnet34 #solid CNN model with 34 layers\n",
    "    - metrics | error_rate\n",
    "- model.resnet34 = downloads pre-trained resnet34 model which has already gone through 1.5 million various images so has pre-trained weights (this is transfer learning)... allows us to train using 1/100 of the needed data and 1/100 of the time\n",
    "- .fit_one_cycle: better than fit, for some reason. Someone wrote a paper. Param = num of epochs (among other things)\n",
    "- how to test accuracy at 0 epochs?\n",
    "- .save(NAME): saves the model as NAME \n",
    "- .load(NAME);loads a previously saved model\n",
    "\n",
    "\n",
    "- *results* (checking whether mistakes are reasonable can be good)\n",
    "    - ClassificationInterpretation.from_learner(MODEL_NAME) can be used to print top losses\n",
    "    - top losses uses loss function for level of confidence vs. error\n",
    "    - use confusion matrix via interp.plot_confusion_matrix (less helpful when high accuracy)\n",
    "    - interp.most_confused is good\n",
    "\n",
    "**Tuning**\n",
    "\n",
    "- *tuning the model*\n",
    "   - the reason the model trains so quicly at first is that we actually add a few nodes to the end and just train these, leaving the rest of the more complex model alone\n",
    "   - using MODEL.unfreeze() allows us to change the earlier layers of the CNN model --> usually this leads to a lower accuracy at first due to equal learning rate across all layers although earlier layers will naturally be stronger \n",
    "   - CNN works by basing the next layer on simple mathematical combinations of the previous layers.\n",
    "   - useful to plot the learning rate vs. accuracy using MODEL.lr_find() --> Use the chart to set learning rate accordingly\n",
    "   - .fit_one_cycle with max_lr=slice(lower,upper) is helpful --> sets the lr for the layers incrementally according to lower - upper. Good idea is to have a lower LR for lower layers and higher LR for higher layers, since LR corresponds to changes each iteration, and the less accurate layers need more changes. \n",
    "- batch size = number of images computed at one time... lower it if you run out of memory\n",
    "- resnet50 is a deeper CNN... loading with larger size images will lead to more accuracy since more details that model can handle. \n",
    "\n",
    "**Other**\n",
    "\n",
    "\n",
    "- There are other ways to get classes of the data:\n",
    "    - from_folder if each folder is it's own class\n",
    "    - from_csv if labels in a csv file\n",
    "    - from_df if labels in a data frame\n",
    "    - from_name_func allows you to define function that converts name to label\n",
    "    - from_lists if you have a list of the labels\n",
    "\n",
    "\n",
    "- All the documentation on fastai is in a Github repo as Jupyter-notebooks, so you can experiment if necessary. Each has examples so learning from them is easy. \n",
    "\n",
    "\n",
    "**Advice**\n",
    "> \"*Run the code*\" <br> \"*Spend the majority of the time in the notebooks*\"\n",
    "\n",
    "\n",
    "\n",
    "- bring deep learning into my passion\n",
    "\n",
    "\n",
    "**ideas for using deep learning with EA:**\n",
    "    - image recognition:\n",
    "        - NGOs \n",
    "    - natural language processing\n",
    "        - government policy biases \n",
    "        - govenment policy high risk statements and views\n",
    "        - twitter and FB feed: EA-esque statements for targetting \n",
    "        - rich people: EA-esqe views and statements for targetted philanthropy\n",
    "        - government tax invoices: corruption identification\n",
    "    - data analysis\n",
    "        - government funding \n",
    "        - foreign aid budget sheets --> predicting success of program \n",
    "\n",
    "\n",
    "- *other*\n",
    "    - bankruptucy: tax invoice analysis \n",
    "    \n",
    "    - If you can create an image from something that isn't an image, you can then apply CNNs (i.e. tracking mouse movement as an image and classification as real or bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
