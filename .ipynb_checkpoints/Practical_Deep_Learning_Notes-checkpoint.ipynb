{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Deep Learning Course Notes\n",
    "\n",
    "*This is a place for random small notes on various functions, packages, tips and more*\n",
    "\n",
    "---\n",
    "**Table of Contents**\n",
    "* 00 Jupyter Notebook tutorial\n",
    "* 01 Image Classification\n",
    "    * A. Tips with RegEx \n",
    "* 02 Data Cleaning and Production; SGD from Scratch\n",
    "* 03 Data blocks; Multi-label classification; Segmentation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    " <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Notebook Tutorial\n",
    "[link to notebook](https://ng8d23p8.gradient.paperspace.com/notebooks/course-v3/nbs/dl1/00_notebook_tutorial-1-my-copy.ipynb)\n",
    "\n",
    "\n",
    "**Cool to do list tricks**\n",
    "\n",
    "- [x] Take notes\n",
    "    - [x] start course\n",
    "\n",
    "1. step 1\n",
    "    2. step 2\n",
    "    \n",
    "* my\n",
    "* name\n",
    "* is \n",
    "\n",
    "**Cool tricks**\n",
    "\n",
    "`m` to change cell to markdown\n",
    "\n",
    "`?function-name` to display parameters\n",
    "\n",
    "`D + D` to delete a cell\n",
    "\n",
    "`esc` to go to command from edit mode\n",
    "\n",
    "`b` create new cell\n",
    "\n",
    "`shift` + `enter`: run current cell\n",
    "\n",
    ">*\"She said do you love me\"*\n",
    "\n",
    "\n",
    "\n",
    "**Display Images**\n",
    "\n",
    "> from PIL import Image <br> Image.open('images/notebook_tutorial/cat_example.jpg')\n",
    "\n",
    "<br> \n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Classification\n",
    "[link to lecture](https://course.fast.ai/videos/?lesson=1) <br>\n",
    "[link to notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson1-pets.ipynb)\n",
    "\n",
    "\n",
    "### Notes\n",
    "\n",
    "**Loading the Data**\n",
    "- Untar data function: downloads the dataset as a tgz file and returns the data path to the file \n",
    "- Path data type: POSIX path while path.ls() lists the files in the path\n",
    "- Image data bunch.from_name_re: (some has to do with imagedatabunch and some with the method of retrieval)\n",
    "    - size 224 --> all images must be the same size\n",
    "    - regular expression --> to take fname and convert to a class\n",
    "    - path --> the path to the images\n",
    "    - file names --> names of images \n",
    "    - transforms = crop + resize + padding (data augmentation) the images \n",
    "    - batch size \n",
    "- regular expression: string matching operations to retrieve information [more](https://docs.python.org/3.6/library/re.html)\n",
    "- normalize: Must normalize the data\n",
    "    - each red, blue, green channel need a mean & st.dev of 0 and 1 to perform\n",
    "- Data bunch object (essentially returns a dataloader) \n",
    "    - training data\n",
    "    - validation data\n",
    "    - test data (optional)\n",
    "    - property c = # of classes (or similar) \n",
    "- data.show_batch and data.classes: shows example data points and all classes\n",
    "\n",
    "**Training and fitting**\n",
    "\n",
    "- (Conv)Learner: a type of method that learns and fits data (cnn_learner)\n",
    "    - data | images\n",
    "    - model/architecture | model.resnet34 #solid CNN model with 34 layers\n",
    "    - metrics | error_rate\n",
    "- model.resnet34 = downloads pre-trained resnet34 model which has already gone through 1.5 million various images so has pre-trained weights (this is transfer learning)... allows us to train using 1/100 of the needed data and 1/100 of the time\n",
    "- .fit_one_cycle: better than fit, for some reason. Someone wrote a paper. Param = num of epochs (among other things)\n",
    "- how to test accuracy at 0 epochs?\n",
    "- .save(NAME): saves the model as NAME \n",
    "- .load(NAME);loads a previously saved model\n",
    "\n",
    "\n",
    "- *results* (checking whether mistakes are reasonable can be good)\n",
    "    - ClassificationInterpretation.from_learner(MODEL_NAME) can be used to print top losses\n",
    "    - top losses uses loss function for level of confidence vs. error\n",
    "    - use confusion matrix via interp.plot_confusion_matrix (less helpful when high accuracy)\n",
    "    - interp.most_confused is good\n",
    "\n",
    "**Tuning**\n",
    "\n",
    "- *tuning the model*\n",
    "   - the reason the model trains so quicly at first is that we actually add a few nodes to the end and just train these, leaving the rest of the more complex model alone\n",
    "   - using MODEL.unfreeze() allows us to change the earlier layers of the CNN model --> usually this leads to a lower accuracy at first due to equal learning rate across all layers although earlier layers will naturally be stronger \n",
    "   - CNN works by basing the next layer on simple mathematical combinations of the previous layers.\n",
    "   - useful to plot the learning rate vs. accuracy using MODEL.lr_find() --> Use the chart to set learning rate accordingly\n",
    "   - .fit_one_cycle with max_lr=slice(lower,upper) is helpful --> sets the lr for the layers incrementally according to lower - upper. Good idea is to have a lower LR for lower layers and higher LR for higher layers, since LR corresponds to changes each iteration, and the less accurate layers need more changes. \n",
    "- batch size = number of images computed at one time... lower it if you run out of memory\n",
    "- resnet50 is a deeper CNN... loading with larger size images will lead to more accuracy since more details that model can handle. \n",
    "\n",
    "**Other**\n",
    "\n",
    "\n",
    "- There are other ways to get classes of the data:\n",
    "    - from_folder if each folder is it's own class\n",
    "    - from_csv if labels in a csv file\n",
    "    - from_df if labels in a data frame\n",
    "    - from_name_func allows you to define function that converts name to label\n",
    "    - from_lists if you have a list of the labels\n",
    "\n",
    "\n",
    "- All the documentation on fastai is in a Github repo as Jupyter-notebooks, so you can experiment if necessary. Each has examples so learning from them is easy. \n",
    "\n",
    "\n",
    "**Advice**\n",
    "> \"*Run the code*\" <br> \"*Spend the majority of the time in the notebooks*\"\n",
    "\n",
    "\n",
    "\n",
    "- bring deep learning into my passion\n",
    "\n",
    "\n",
    "**ideas for using deep learning with EA:**\n",
    "    - image recognition:\n",
    "        - NGOs \n",
    "    - natural language processing\n",
    "        - government policy biases \n",
    "        - govenment policy high risk statements and views\n",
    "        - twitter and FB feed: EA-esque statements for targetting \n",
    "        - rich people: EA-esqe views and statements for targetted philanthropy\n",
    "        - government tax invoices: corruption identification\n",
    "    - data analysis\n",
    "        - government funding \n",
    "        - foreign aid budget sheets --> predicting success of program \n",
    "\n",
    "\n",
    "- *other*\n",
    "    - bankruptucy: tax invoice analysis \n",
    "    \n",
    "    - If you can create an image from something that isn't an image, you can then apply CNNs (i.e. tracking mouse movement as an image and classification as real or bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Tips with regular expressions\n",
    "\n",
    "[video on RegEx](https://www.youtube.com/watch?v=DRR9fOXkfRE&feature=youtu.be) \n",
    "\n",
    "#### RegEx\n",
    "*Regular expressions allow us to search text for strings that match some defined expression like searching a list of names for all the Jennifers or selecting all the addresses on a specific street from a list*\n",
    "\n",
    "They can be especially useful for **Machine Learning** as they can be used to scrap data from websites and lists of text\n",
    "\n",
    "An example of a RegEx that searches for all the first and last names of Jennifers would be:\n",
    ">`'(Jennifer|Jen|Jenny)\\b\\w+\\b'`\n",
    "\n",
    "> `|` or \n",
    "<br> `\\b` any line space \n",
    "<br> `w+` 1 or more chars \n",
    "\n",
    "**Furthermore, other useful variables include:**\n",
    "\n",
    "> `\\s` space \n",
    "<br> `d` digit\n",
    "<br> `d{1,5}` 1-5 digits \n",
    "<br> `D` anything but a digit\n",
    "<br> `.` anything\n",
    "<br> `\\.` a period\n",
    "\n",
    "But this is just a few of the countless things RegEx expressions can use\n",
    "\n",
    "**Python Code**\n",
    "> `import re` to import regular expressions\n",
    "<br> `re.compile('w+\\b\\st\\.\\b.')` to define a RegEx for use\n",
    "<br> `re.search(RegEx,String)` to return the first instance of a RegEx in a String\n",
    "<br> `.group()` to return a found instance of a RegEx\n",
    "<br> `.span()` to return the indices which the RegEx was found at in the text (start,end)\n",
    "<br> `.findall(RegEx,String)` to find all instances of a RegEx in a String\n",
    "<br> `.split(String)` to print an array of strings split up by the RegEx (i.e. those that aren't the RegEx)\n",
    "<br> `.sub(TextToSub,String)` to substitute text for the RegEx in a String (RegEx is defined before calling this)\n",
    "\n",
    "This are many more useful ways to implement Regular Expressions. See this [series](https://www.youtube.com/watch?v=FCFdgymqpUI) of videos to continue learning. \n",
    "\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning and production; SGD from Scratch\n",
    "The first part of this lesson focuses on implementing a CNN model with images scraped from the internet. It goes through the process of locating the images, downloading them, creating the model, training the model and testing the model. It also goes through removing noisy images, saving the model for production, using the model for inference and uploading the model as a web app. Finally, it touches on ways for a CNN model to go wrong. \n",
    "\n",
    "The second part of this lesson has us implement Stochastic Gradient Descent from scratch on a linear dataset for linear regression.\n",
    "\n",
    "\n",
    "1. [lecture](https://course.fast.ai/videos/?lesson=2) <br>\n",
    "2. [CNN slides](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb)\n",
    "3. [Gradient Descent slides](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-sgd.ipynb)\n",
    "\n",
    "--- \n",
    "\n",
    "### Data cleaning and production\n",
    "\n",
    "\n",
    "**Get images from google** <br>\n",
    "*This downloads a CSV of all the urls*\n",
    "\n",
    "1. Search Google Images & load all the images you want\n",
    "2. Enter the following code after pressing `cmd-Opt-j`\n",
    ">`urls=Array.from(document.querySelectorAll('.rg_i')).map(el=> el.hasAttribute('data-src')?el.getAttribute('data-src'):el.getAttribute('data-iurl'));` <br> `window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));`\n",
    "\n",
    "**Download images from CSV** <br>\n",
    "*We can use fastai's download_images to save a folder of all the urls downloaded*\n",
    "> `download_images(path/file, dest, max_pics=200,max_workers=0)` #include max_workers = 0 if error\n",
    "\n",
    "Note: `path` is of the format `Path` or PosixPath\n",
    "\n",
    "**Cleaning up** <br>\n",
    "Then *we can use verify_images to filter out all non-images*\n",
    "> `verify_images(path/c, delete=True, max_size=500)` where c is the folder name\n",
    "\n",
    "Finally, we can use `FileDeleter` to go through the `most_confused` and manually delete any noisy images\n",
    "\n",
    "**Using CNN for Inference and a Web App** \n",
    "- ipy widgets can be used to create small applications in notebook that are useful\n",
    "    - Example: FileDeleter allows us to go through images in the notebook, deleting noisy data. \n",
    "- `ImageDataBunch.single_from_classes` loads a pretrained model from specified path and still must apply the `create_cnn` method with same parameters as well as `.load` the right model #you'd do this when loading up the web app\n",
    "- use `learn.predict(img)` to get the predicted label \n",
    "\n",
    "**Things Gone Wrong**\n",
    "1. Learning Rate is too high (i.e. 0.5?)\n",
    "    1. validation loss will be very large\n",
    "2. Learning Rate is too low (i.e. 0.000001)\n",
    "    1. validation loss might be larger than training loss, which means we are not fitting the data\n",
    "    2. The rate of decrease in the validation loss or error is very slow compared to the default\n",
    "> `learn.recorder.plot_losses()` can be used to plot the losses over time \n",
    "3. Too few epochs (i.e. 1)\n",
    "    1. If the training loss is much larger than the validation loss, this is a sign. \n",
    "    2. Solution: Increase # epochs and learning rate (if too slow)\n",
    "4. Overfitting (very hard with CNNs)\n",
    "    1. The sign is that the error gets better and then worse\n",
    "5. Too little data \n",
    "    1. The learning rate is optimal and your error rate has began getting worse, but you're not happy with the accuracy\n",
    "    \n",
    "---\n",
    "\n",
    "### SGD from Scratch\n",
    "\n",
    "**Overview**\n",
    "* Machine Learning algorithms like `ResNet34` are just functions applied to the pixel representation of an image\n",
    "    * Thus very useful tools for working with them include linear algebra, matrices, dot products, etc. \n",
    "* PyTorch does not like loops, so we generally want to use lin. alg. to do everything at once\n",
    "\n",
    "**PyTorch and other useful code**\n",
    "* tensor is a data type, basically a matrix or a tuple, where the array is regular (i.e. rectangle, 3D-rectangular prism, etc.)\n",
    "* `x@a` performs matrix multiplication on x and a (python function but overwritten with PyTorch)\n",
    "* `torch.rand(n)` returns n random numbers between 0 and 1 \n",
    "* `x[:,0].uniform_(-1.,1)` fills all of specified indices of x with a random number uniformally chosen between -1 and 1(python and PyTorch function) **Note:** that the underscore signifies *replace* not *return*\n",
    "* `torch.ones(shape)` returns a tensor of the shape given with all 1's\n",
    "* `tensor.type` returns the type (float, int, etc.) --> important to add use a `.` to have float type\n",
    "* `plt.scatter(x,y)` can be easily used to visualize\n",
    "* MatPlotLib's `animation.FuncAnimation` method takes in a figure, *animate* method, number of times n, time interval for plotting \n",
    "    * the `figure` is what you would plot the animation on\n",
    "    * `animate` is called `n` times, where it may update and return a line to be plotted\n",
    "    * `interval` is how long between successive plots of lines\n",
    "\n",
    "**Stochastic Gradient Descent implementation**\n",
    "\n",
    "* it is possible to calculate the mse really quickly like so: `def mse(y_hat, y): return ((y_hat-y)**2).mean()`\n",
    "* furthermore, *PyTorch* will actually remember how you calculated the loss, so it can calculate the gradient for you through `loss.backward()` where `loss=mse(y_hat,y)`\n",
    "* `a.sub_(lr * a_grad)` will replace `a` with `a - lr * gradient` \n",
    "    * we want to *subtract* since the gradient naturally points us towards *maximizing* the function\n",
    "* we also will want to set the gradient to zero after updating through `a.grad.zero()`\n",
    "* the full code for simple gradient descent can be found [here](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-sgd.ipynb)\n",
    "\n",
    "**Vocab** \n",
    "* In reality, we use **Stoch Grad mini-batch Descent** since we cannot afford to computationally look at every single data point when updating each round, where look at random indices each loop \n",
    "* **Learning Rate**: how much to update weights \n",
    "* Once we have seen every image, we count it as one **epoch**. We don't want to do too many **epochs** since the more times we see an image, the higher chance we have of over-fitting\n",
    "* The **model** or **architecture** is the mathematical equation that we fit the parameters to\n",
    "* The **parameters** are the numbers we're updating and are specific to the data\n",
    "* Finally, the **loss function** is what tells us how far away we are from being correct\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Data blocks; Multi-label classification; Segmentation\n",
    "\n",
    "\n",
    "\n",
    "[lecture](https://course.fast.ai/videos/?lesson=3) <br>\n",
    "\n",
    "**Notebooks**\n",
    "* [multi-label prediction with amazon dataset](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-planet.ipynb) <br>\n",
    "* [image segmentation with cam vid](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb) <br>\n",
    "* [IMBD](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb) <br>\n",
    "* [regression with head pose data](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-head-pose.ipynb)\n",
    "\n",
    "--- \n",
    "\n",
    "**general**\n",
    "- for a general guide on downloading and using Kaggle datasets, see the first part of [this notebook](https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-planet.ipynb)\n",
    "\n",
    "### Data blocks\n",
    "- one of the trickiest steps in DL is loading and pre-processing the data (i.e. getting it into a form that can be used by a model). In `fastai` there is a [data block api](https://docs.fast.ai/data_block.html) that makes it easy.\n",
    "- `DataLoader` is a PyTorch class that combines a dataset and a sampler (i.e. batch size) and provides an iterable over\n",
    "- `DataBunch` class uses PyTorch's `DataLoader` class to define the training, validation and possible test datasets\n",
    "- The [Data block API](https://docs.fast.ai/data_block.html) has a bunch of different functions that combine to create a `DataBunch`\n",
    "> 1. What are the inputs & how to create them i.e.`ImageList.from_csv(path, 'train_v2.csv', folder='train-jpg', suffix='.jpg')`   <br>2. How to split the data into training & validation sets i.e. `.split_by_rand_pct(0.2)` <br> 3. How to label the inputs i.e. `label_from_df(label_delim=' ')` <br> 4. What transforms to apply i.e. `.transform(tsfm,128)` <br> 5. How to add a test set? <br> 6. How to wrap in `dataloaders` and create the DataBunch i.e. `.databunch(param)`\n",
    "- see [this notebook](https://github.com/fastai/fastai/blob/master/docs_src/data_block.ipynb) for more examples\n",
    "- `get_transforms` takes in a bunch of different parameters. Some to note include:\n",
    "> `do_flip` and `vert_flip` default to true and false and are used to randomly flip the images so they generalize more <br> `max_rotate` is used to randomly rotate images <br> `max_warp` is used to randomly warp images which can be useful since pictures of objects aren't always taken from the same view <br> `max_lighting` is used to adjust the lighting \n",
    "\n",
    "### Multi-label classification\n",
    "\n",
    "- Play around with the metrics for multi-class and threshold\n",
    "- It's very easy to look at the source code for how the Data block API works... so if at any point you need to do something that it isn't built for, it's likely that you'll be able to just make a quick function based on the source code that does what you need. \n",
    "- ImageFileList and other things that you .from_folder on are found under the applications part of the doc \n",
    "- Specific LR playing around with stuff (look at lesson notes)\n",
    "- Using smaller images to benefit through transfer learning\n",
    "    * idea is that we can take our finely tuned model on the smaller images and then, fine tune it more on the larger images, which by nature of them being larger, will be entirely different, so we can train the model more and not worry about overfitting\n",
    "\n",
    "### Image Segmentation\n",
    "The idea is to take an image and classify each pixel as belonging to some set of classes which can be represented in the image. It requires that the dataset for training have each pixel of an image classified, which is a lot of work to do, so most of the time you will probably implement image segmentation on a pre-prepared dataset. \n",
    "\n",
    "\n",
    "Questions:\n",
    "- For torch.dataset, if the indexing isn't defined, how can we retrieve one datapoint? Is it the dataloader method? (Look at source code)\n",
    "- How to fit a learner on specific data (i.e. new data or misclassified data)? \n",
    "- How would I create a dataset for image segmentation?\n",
    "\n",
    "Exercise:\n",
    "- make a web app with the models generated in this lesson \n",
    "- go through the source code for the Data Block api & the ImageList, ImageDataBunch, etc. in the vision section \n",
    "\n",
    "Today's to do:\n",
    "- create a forum account and go over some relevant posts & pages\n",
    "- go through the source code for data block api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## To do\n",
    "\n",
    "* [x] create a Github repo for all of this\n",
    "* [x] apply a CNN to some scraped images\n",
    "* [ ] create a web app for a CNN\n",
    "    - free hosting can be found online\n",
    "    - starlette is supposed to be good \n",
    "* [ ] start a kaggle competition\n",
    "    * set up the API\n",
    "    * include train, val split\n",
    "    * submit something & get a score \n",
    "* [ ] apply a CNN to something EA related\n",
    "* [ ] imagify some data and then apply a CNN \n",
    "* [ ] create a useful CNN production online (maybe on my website or blog) \n",
    "* [ ] create an ipy widget\n",
    "* [ ] write technical blog post about CNN applications and first 2 lessons\n",
    "* [ ] find an ML mentor\n",
    "* [ ] do a short git version control course\n",
    "* [ ] contribute to fastai repo \n",
    "* [ ] do/skim the [computational linear algebra course](https://github.com/fastai/numerical-linear-algebra/blob/master/README.md) \n",
    "* [ ] do PyTorch [course](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "\n",
    "\n",
    "**Ideas**\n",
    "\n",
    "* Physical Look classification or 'How do I look?' *could use segmentation to separate face and each article of clothing, multi-label to label it as multiple things, etc.*\n",
    "    * Skin care or acne  \n",
    "    * Sleepy\n",
    "    * How's the hair? (neat, messy but on point, rolled out of bed) \n",
    "    * Clothes match \n",
    "    * Attire (business casual, casual, beach day, sports, etc.) \n",
    "    * How does it fit? (man vs. women, classify which type of clothing, optimal fit for each type) \n",
    "    * Need ironing?\n",
    "    * Mood of outfit (happy, sad, dark, serious, playful, etc.)  \n",
    "\n",
    "\n",
    "* Something to go with drones *drones are being used for all sorts of things... what's a useful visual ML application that would be complimentary?*  \n",
    "\n",
    "* Bike need fixing? Take a picture of various parts of a bike and it tells you what needs to get done\n",
    "\n",
    "* for open source, diving deep into using `fastai` might lead to small things that can be improved or added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
